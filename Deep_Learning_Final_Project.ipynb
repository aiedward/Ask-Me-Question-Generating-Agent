{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFKW-B7DBhWs",
    "colab_type": "text"
   },
   "source": [
    "## Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "eTBc5W1r_ez0",
    "colab_type": "code",
    "outputId": "4cc56399-b602-4996-8cdc-645ad104b48f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CS-7643-Deep-Learning-Final-Project'...\n",
      "remote: Enumerating objects: 193, done.\u001b[K\n",
      "remote: Counting objects: 100% (193/193), done.\u001b[K\n",
      "remote: Compressing objects: 100% (137/137), done.\u001b[K\n",
      "remote: Total 193 (delta 88), reused 150 (delta 47), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (193/193), 31.53 MiB | 18.91 MiB/s, done.\n",
      "Resolving deltas: 100% (88/88), done.\n",
      "mkdir: cannot create directory ‘data’: File exists\n",
      "mkdir: cannot create directory ‘dataset’: File exists\n"
     ]
    }
   ],
   "source": [
    "!rm *.py\n",
    "!git clone https://github.com/tanmaybinaykiya/CS-7643-Deep-Learning-Final-Project.git \n",
    "!mv CS-7643-Deep-Learning-Final-Project/*.py .\n",
    "!rm -rf 'CS-7643-Deep-Learning-Final-Project'\n",
    "!mkdir data\n",
    "!mkdir dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaC4zPb0Bm9m",
    "colab_type": "text"
   },
   "source": [
    "## Download datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQBz1oPtEMMx",
    "colab_type": "text"
   },
   "source": [
    "### Download GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3plbto4sATqB",
    "colab_type": "code",
    "outputId": "49f03680-46fc-4782-bcd4-992b62a7ae4f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-11-26 01:47:58--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
      "--2018-11-26 01:47:58--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2176768927 (2.0G) [application/zip]\n",
      "Saving to: ‘glove.840B.300d.zip’\n",
      "\n",
      "glove.840B.300d.zip 100%[===================>]   2.03G  37.2MB/s    in 46s     \n",
      "\n",
      "2018-11-26 01:48:44 (45.2 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
      "\n",
      "Archive:  glove.840B.300d.zip\n",
      "  inflating: glove.840B.300d.txt     \n"
     ]
    }
   ],
   "source": [
    "!wget 'http://nlp.stanford.edu/data/glove.840B.300d.zip'\n",
    "!unzip 'glove.840B.300d.zip'\n",
    "!rm glove.840B.300d.zip\n",
    "!mv glove.840B.300d.txt data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCs2uHw_E4Eg",
    "colab_type": "text"
   },
   "source": [
    "### Download Squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uQW1WAxfE6hh",
    "colab_type": "code",
    "outputId": "305bf8e8-395e-4d27-9ff3-45c0c173aff7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘dataset’: File exists\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 28.8M  100 28.8M    0     0  24.4M      0  0:00:01  0:00:01 --:--:-- 24.4M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 4740k  100 4740k    0     0  4090k      0  0:00:01  0:00:01 --:--:-- 4090k\n"
     ]
    }
   ],
   "source": [
    "!mkdir dataset\n",
    "!curl -o 'dataset/squad-train-v1.1.json' 'https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json' \n",
    "!curl -o 'dataset/squad-dev-v1.1.json' 'https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApeYvHvdEr1z",
    "colab_type": "text"
   },
   "source": [
    "### Data Preprocessor\n",
    "\n",
    "Builds question answer pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VFIX6bslHJvX",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51.0
    },
    "outputId": "542385eb-4ac8-4fb2-e2c4-84779fc246a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from DataProcessor import main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wXnjydqOArZG",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425.0
    },
    "outputId": "855f943e-07c9-48a1-f2be-9b31e3c7d34c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/answer_glove_embeddings.npy doesn't exist. Pruning...\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'mylot.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'Amazon.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "data/question_glove_embeddings.npy doesn't exist. Pruning...\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'mylot.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n",
      "Error occured but ignored  could not convert string to float: 'Amazon.com'\n",
      "Error occured but ignored  could not convert string to float: 'name@domain.com'\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjLpkRPDH-Tg",
    "colab_type": "text"
   },
   "source": [
    "# Install Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ooZIyL4IViP",
    "colab_type": "text"
   },
   "source": [
    "## Install Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SHRAYI5xH9Ch",
    "colab_type": "code",
    "outputId": "06fe880b-9f34-48d9-bba9-5ca0b6ebef19",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "platform, accelerator: cp36-cp36m cu80\n",
      "Collecting torch==0.4.0 from http://download.pytorch.org/whl/cu80/torch-0.4.0-cp36-cp36m-linux_x86_64.whl\n",
      "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.4.0-cp36-cp36m-linux_x86_64.whl (484.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 484.0MB 50.3MB/s \n",
      "tcmalloc: large alloc 1073750016 bytes == 0x5b25a000 @  0x7fd56a1ca2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
      "\u001b[?25hCollecting torchvision\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
      "Collecting pillow>=4.1.1 (from torchvision)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 2.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
      "Installing collected packages: torch, pillow, torchvision\n",
      "  Found existing installation: Pillow 4.0.0\n",
      "    Uninstalling Pillow-4.0.0:\n",
      "      Successfully uninstalled Pillow-4.0.0\n",
      "Successfully installed pillow-5.3.0 torch-0.4.0 torchvision-0.2.1\n"
     ]
    }
   ],
   "source": [
    "# http://pytorch.org/\n",
    "from os import path\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "print(\"platform, accelerator:\", platform, accelerator)\n",
    "!pip install -v -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mo2GBaSwFWiN",
    "colab_type": "text"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aH08hQ4O6DEC",
    "colab_type": "text"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "f4-Suc4L6B4e",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from constants import DatasetPaths\n",
    "\n",
    "from DataLoader import SquadDataset, collate_fn, GloVeEmbeddings\n",
    "from models import EncoderBILSTM, DecoderLSTM\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJGRpcwh6I1W",
    "colab_type": "text"
   },
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "4rj8LUuihHKZ",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import numpy as np\n",
    "\n",
    "def plot_losses(losses):\n",
    "  plt.plot(losses)\n",
    "\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.title('Loss vs Epoch')\n",
    "  plt.grid(True)\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "g6zuBz9pFTZo",
    "colab_type": "code",
    "outputId": "ddc02113-4f4b-4fba-f467-50d7a966632e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for the batch is 193.961199\n",
      "Loss for the batch is 120.247938\n",
      "Loss for the batch is 28.643003\n",
      "Loss for the batch is 23.283130\n",
      "Loss for the batch is 56.955405\n",
      "Loss for the batch is 36.279672\n",
      "Loss for the batch is 47.597317\n",
      "Loss for the batch is 33.824320\n",
      "Loss for the batch is 27.154412\n",
      "Loss for the batch is 8.664672\n"
     ]
    }
   ],
   "source": [
    "use_cuda=True\n",
    "use_cuda = use_cuda and torch.cuda.is_available()\n",
    "\n",
    "train_dataset = SquadDataset(split=\"train\")\n",
    "word_to_idx_sent = train_dataset.get_answer_word_to_idx()\n",
    "word_to_idx_q = train_dataset.get_question_idx_to_word()\n",
    "\n",
    "train_vocab_size_sent = len(word_to_idx_sent)\n",
    "train_vocab_size_q = len(word_to_idx_q)\n",
    "num_epoch = 40\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=collate_fn,\n",
    "                          pin_memory=True)\n",
    "\n",
    "word_embeddings_glove_q = GloVeEmbeddings.load_glove_embeddings(True)\n",
    "word_embeddings_glove_sent = GloVeEmbeddings.load_glove_embeddings(False)\n",
    "\n",
    "encoder = EncoderBILSTM(vocab_size=train_vocab_size_sent, n_layers=2, embedding_dim=300, hidden_dim=500,\n",
    "                        dropout=0, embeddings=word_embeddings_glove_sent)\n",
    "decoder = DecoderLSTM(vocab_size=train_vocab_size_q, embedding_dim=300, hidden_dim=500, n_layers=1,\n",
    "                      encoder_hidden_dim=500, embeddings=word_embeddings_glove_q)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()\n",
    "\n",
    "n_train = len(train_loader)\n",
    "batch_per_epoch = n_train // batch_size\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer_enc = torch.optim.SGD(encoder.parameters(), lr=1.0)\n",
    "optimizer_dec = torch.optim.SGD(decoder.parameters(), lr=1.0)\n",
    "\n",
    "if not os.path.isdir(\"model_weights\"):\n",
    "    os.makedirs(\"model_weights\", exist_ok=True)\n",
    "\n",
    "losses= train(encoder, decoder, num_epoch, batch_per_epoch, train_loader, criterion, optimizer_enc, optimizer_dec, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "cRQ74JUF9Whj",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "plot_losses(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "79N4KGVZBpXU",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "dev_dataset = SquadDataset(split=\"dev\")\n",
    "\n",
    "dev_loader = DataLoader(\n",
    "    dev_dataset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn=collate_fn, pin_memory=True)\n",
    "dev_idx_to_word_q = dev_dataset.get_question_idx_to_word()\n",
    "dev_idx_to_word_a = dev_dataset.get_answer_idx_to_word()\n",
    "greedy_search(encoder, decoder, dev_loader, True, dev_idx_to_word_q, dev_idx_to_word_a)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Deep Learning Final Project",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
